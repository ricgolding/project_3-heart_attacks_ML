{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54613554-ee56-497b-b48c-c367518d9a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "df = pd.read_csv('../data/heart_attack_prediction_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b63930-698e-4826-a9da-e31f3b0dbd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cf5e73-9b7b-49d0-8f8a-0f88bfb1c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460554b7-7fc3-4ce5-bcb8-5a719399bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4bdfcb-0c76-4d9b-91be-b15f1b51129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making column titles consistent\n",
    "df.columns = [column.lower().replace(\" \",\"_\") for column in df.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2104de-d36a-4333-a1ee-c8c6baecab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing blood_pressure column into two. First number is systolic pressure and second\n",
    "#is diastolic pressure\n",
    "\n",
    "df['systolic_pressure'] = df['blood_pressure'].apply(lambda x: x.split(\"/\")[0])\n",
    "df['diastolic_pressure'] = df['blood_pressure'].apply(lambda x: x.split(\"/\")[1])\n",
    "df = df.drop(columns='blood_pressure')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cb5027-c5bd-46e7-ae01-9c96fc1e9d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='patient_id',inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e577cfc-5916-4b2e-8e40-09ca3212fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['continent','hemisphere'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdfa099-4fa5-4315-8791-594132807923",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change heart attack risk to boolean\n",
    "\n",
    "df['heart_attack_risk'] = df['heart_attack_risk'].astype(int)\n",
    "df['systolic_pressure'] = df['systolic_pressure'].astype(int)\n",
    "df['diastolic_pressure'] = df['diastolic_pressure'].astype(int)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56faeca6-4716-49fd-96c4-a150e5152905",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcef9bae-00f6-4131-b414-b2b49915b068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUICK EDA\n",
    "\n",
    "subset1 = df.iloc[:, 0:5]\n",
    "subset1['heart_attack_risk'] = df['heart_attack_risk']\n",
    "\n",
    "sns.pairplot(subset1, hue='heart_attack_risk',height=2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a700699e-3598-47c8-819a-bd14a0cd85c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset2 = df.iloc[:, 6:11]\n",
    "subset2['heart_attack_risk'] = df['heart_attack_risk']\n",
    "\n",
    "sns.pairplot(subset2, hue='heart_attack_risk',height=2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b87720-6c54-4f71-b0c7-1f33509a8d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset3 = df.iloc[:, 12:17]\n",
    "subset3['heart_attack_risk'] = df['heart_attack_risk']\n",
    "\n",
    "sns.pairplot(subset3, hue='heart_attack_risk',height=2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6490ef43-bb1b-4d72-a63f-5ab920252a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset4 = df.iloc[:, 18:22]\n",
    "subset4['heart_attack_risk'] = df['heart_attack_risk']\n",
    "\n",
    "sns.pairplot(subset4, hue='heart_attack_risk',height=2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19731e7d-1712-4858-817b-e789c0260ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset5 = df.iloc[:, 23:26]\n",
    "subset5['heart_attack_risk'] = df['heart_attack_risk']\n",
    "\n",
    "sns.pairplot(subset5, hue='heart_attack_risk',height=2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cfe6b5-8268-4fbe-b494-fa507d210e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = df.select_dtypes(include='number')\n",
    "\n",
    "\n",
    "corr=np.abs(numerical_columns.corr()) # corr(x,y) = corr(y, x), corr(x,x) = 1\n",
    "\n",
    "#Set up mask for triangle representation\n",
    "mask = np.zeros_like(corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(20, 20))\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask,  vmax=1,square=True, linewidths=.5, cbar_kws={\"shrink\": .5},annot = corr)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06e4e60-8cb5-490c-ba61-63ae1bb3279f",
   "metadata": {},
   "source": [
    "### Balance Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a883d3-6ab9-42d8-a66b-dc6edf5bbfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_attack_risk = df['heart_attack_risk'].value_counts()\n",
    "heart_attack_risk.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b63caeb-6a26-4059-b773-957fc33696a4",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e785d75f-64ee-417c-b29c-65d8f2cc63e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "risk = df[df['heart_attack_risk'] == 1]\n",
    "no_risk = df[df['heart_attack_risk'] == 0]\n",
    "\n",
    "len(risk),len(no_risk)\n",
    "\n",
    "yes_oversampled = resample(risk, replace=True, n_samples = len(no_risk), random_state=0)\n",
    "\n",
    "over_sampling = pd.concat([yes_oversampled, no_risk])\n",
    "\n",
    "heart_attack_risk_plt = over_sampling['heart_attack_risk'].value_counts()\n",
    "heart_attack_risk_plt.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5e016f-8745-4206-8431-82c686312c41",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d29b787-0fcb-4b63-a64e-b8b5109ea79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_heart_attack_undersampled = resample(no_risk,\n",
    "                                    replace=False,\n",
    "                                    n_samples = len(risk),\n",
    "                                    random_state=0)\n",
    "\n",
    "under_sampling = pd.concat([no_heart_attack_undersampled, risk])\n",
    "\n",
    "no_heart_attack_undersampled.plt = under_sampling['heart_attack_risk'].value_counts()\n",
    "no_heart_attack_undersampled.plt.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c059b90-d87a-4f79-826d-1255f0c00202",
   "metadata": {},
   "source": [
    "### Normalization and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ed5314-8395-42fb-82d5-2d6a2db64064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMERICAL TRANSFORMATION\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "over_sampling = over_sampling.reset_index(drop=True)  # Reset index if needed\n",
    "\n",
    "#OneHotEncoder categorical columns\n",
    "df_categorical_columns = over_sampling[['diabetes','family_history','smoking','obesity','alcohol_consumption','diet','previous_heart_problems','medication_use','sex','country']]\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "ohe.fit(df_categorical_columns)\n",
    "\n",
    "cat_trans_np = ohe.transform(df_categorical_columns)\n",
    "cat_df = pd.DataFrame(cat_trans_np, columns=ohe.get_feature_names_out())\n",
    "\n",
    "#Normalizing numerical columns\n",
    "df_numerical_columns = over_sampling[[\"age\",\"cholesterol\",\"heart_rate\",\"exercise_hours_per_week\",\"stress_level\",\"sedentary_hours_per_day\",\"income\",\"bmi\",\"triglycerides\",\"physical_activity_days_per_week\",\"systolic_pressure\",\"diastolic_pressure\"]]\n",
    "normalizer = MinMaxScaler()\n",
    "normalizer.fit(df_numerical_columns)\n",
    "\n",
    "num_trans_np = normalizer.transform(over_sampling[[\"age\",\"cholesterol\",\"heart_rate\",\"exercise_hours_per_week\",\"stress_level\",\"sedentary_hours_per_day\",\"income\",\"bmi\",\"triglycerides\",\"physical_activity_days_per_week\",\"systolic_pressure\",\"diastolic_pressure\"]])\n",
    "num_df = pd.DataFrame(num_trans_np, columns = df_numerical_columns.columns, index=over_sampling.index)\n",
    "\n",
    "df_norm_over = pd.concat([num_df, cat_df], axis=1)\n",
    "df_norm_over[\"heart_attack_risk\"] = over_sampling[\"heart_attack_risk\"]\n",
    "df_norm_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b53e2a-a925-4066-9b31-fef7e26b3f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMERICAL TRANSFORMATION\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "under_sampling = under_sampling.reset_index(drop=True)  # Reset index if needed\n",
    "\n",
    "#OneHotEncoder categorical columns\n",
    "df_categorical_columns = under_sampling[['diabetes','family_history','smoking','obesity','alcohol_consumption','diet','previous_heart_problems','medication_use','sex','country']]\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "ohe.fit(df_categorical_columns)\n",
    "\n",
    "cat_trans_np = ohe.transform(df_categorical_columns)\n",
    "cat_df = pd.DataFrame(cat_trans_np, columns=ohe.get_feature_names_out())\n",
    "\n",
    "#Normalizing numerical columns\n",
    "df_numerical_columns = under_sampling[[\"age\",\"cholesterol\",\"heart_rate\",\"exercise_hours_per_week\",\"stress_level\",\"sedentary_hours_per_day\",\"income\",\"bmi\",\"triglycerides\",\"physical_activity_days_per_week\",\"systolic_pressure\",\"diastolic_pressure\"]]\n",
    "normalizer = MinMaxScaler()\n",
    "normalizer.fit(df_numerical_columns)\n",
    "\n",
    "num_trans_np = normalizer.transform(under_sampling[[\"age\",\"cholesterol\",\"heart_rate\",\"exercise_hours_per_week\",\"stress_level\",\"sedentary_hours_per_day\",\"income\",\"bmi\",\"triglycerides\",\"physical_activity_days_per_week\",\"systolic_pressure\",\"diastolic_pressure\"]])\n",
    "num_df = pd.DataFrame(num_trans_np, columns = df_numerical_columns.columns, index=under_sampling.index)\n",
    "\n",
    "under_sampling = under_sampling.reset_index(drop=True)  # Reset index if needed\n",
    "\n",
    "df_norm_under = pd.concat([num_df, cat_df], axis=1)\n",
    "df_norm_under[\"heart_attack_risk\"] = under_sampling[\"heart_attack_risk\"]\n",
    "df_norm_under"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efa3a37-8437-43b6-9de7-305784ddc2d5",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53303981-74a0-4afe-8c66-95e92f32ba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = df_norm_over.drop(columns = ['heart_attack_risk'])\n",
    "target = df_norm_over['heart_attack_risk']\n",
    "\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(features, target, test_size = 0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5b2bfe-0341-44c2-98be-a0ceab9108c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_attack_risk_over = df_norm_over['heart_attack_risk'].value_counts()\n",
    "heart_attack_risk_over.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6861fee5-a944-4b50-b42b-7e4648c45448",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_norm_under.drop(columns = ['heart_attack_risk'])\n",
    "target = df_norm_under['heart_attack_risk']\n",
    "\n",
    "X_train_under, X_test_under, y_train_under, y_test_under = train_test_split(features, target, test_size = 0.20, random_state=0)\n",
    "\n",
    "heart_attack_risk_under = df_norm_under['heart_attack_risk'].value_counts()\n",
    "heart_attack_risk_under.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e92a73-d4f3-4d68-bc9c-3465a0d62a65",
   "metadata": {},
   "source": [
    "### KNNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f877dd9b-8bab-42ac-afba-d5437af69d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_over, y_train_over)\n",
    "pred = knn.predict(X_test_over)\n",
    "\n",
    "\n",
    "print(f\"The accuracy of the model is {knn.score(X_test_over, y_test_over)*100: .2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b1e39d-cf1f-4eee-9bc0-679f690d3ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_under, y_train_under)\n",
    "pred = knn.predict(X_test_under)\n",
    "\n",
    "\n",
    "print(f\"The accuracy of the model is {knn.score(X_test_under, y_test_under)*100: .2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05b135c-344a-454d-861c-180ffaa05a0a",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c098fc-f536-4c7c-8816-af439c1e2c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, r2_score\n",
    "\n",
    "bagging_clas_over = BaggingClassifier(DecisionTreeClassifier(max_depth=20), n_estimators=100,  max_samples = 1000)\n",
    "bagging_clas_over.fit(X_train_over, y_train_over)\n",
    "y_pred_test_bag_over = bagging_clas_over.predict(X_test_over)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test_over, y_pred_test_bag_over):.2f}\")\n",
    "print(f\"Precision: {precision_score(y_test_over, y_pred_test_bag_over):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test_over, y_pred_test_bag_over):.2f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test_over, y_pred_test_bag_over):.2f}\")\n",
    "print(f\"R2 score {bagging_clas_over.score(X_test_over, y_test_over):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062dab2d-fe11-4b96-a28c-621c8c60f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_clas_under = BaggingClassifier(DecisionTreeClassifier(max_depth=20), n_estimators=100,  max_samples = 1000)\n",
    "bagging_clas_under.fit(X_train_under, y_train_under)\n",
    "y_pred_test_bag_under = bagging_clas_under.predict(X_test_under)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test_under, y_pred_test_bag_under):.2f}\")\n",
    "print(f\"Precision: {precision_score(y_test_under, y_pred_test_bag_under):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test_under, y_pred_test_bag_under):.2f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test_under, y_pred_test_bag_under):.2f}\")\n",
    "print(f\"R2 score {bagging_clas_under.score(X_test_under, y_test_under):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a3447c-5a79-48a9-bc25-d60e96966875",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed48f1f9-7f9d-4f6a-a675-2a75c99a5900",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_over = RandomForestClassifier(n_estimators=100, max_depth=20)\n",
    "forest_over.fit(X_train_over, y_train_over)\n",
    "y_pred_test_rf_over = forest_over.predict(X_test_over)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test_over, y_pred_test_rf_over):.2f}\")\n",
    "print(f\"Precision: {precision_score(y_test_over, y_pred_test_rf_over):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test_over, y_pred_test_rf_over):.2f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test_over, y_pred_test_rf_over):.2f}\")\n",
    "print(f\"R2 score {forest_over.score(X_test_over, y_test_over):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "face3864-057d-4888-a278-e5df660e2403",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_under = RandomForestClassifier(n_estimators=100, max_depth=20)\n",
    "forest_under.fit(X_train_under, y_train_under)\n",
    "y_pred_test_rf_under = forest_under.predict(X_test_under)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test_under, y_pred_test_rf_under):.2f}\")\n",
    "print(f\"Precision: {precision_score(y_test_under, y_pred_test_rf_under):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test_under, y_pred_test_rf_under):.2f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test_under, y_pred_test_rf_under):.2f}\")\n",
    "print(f\"R2 score {forest_under.score(X_test_under, y_test_under):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2c76cf-ef21-45f3-b918-315d857a6341",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f0873f-93dc-4feb-b2fc-05e339ce037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb_clas_over = GradientBoostingClassifier(max_depth=20, n_estimators=100)\n",
    "gb_clas_over.fit(X_train_over, y_train_over)\n",
    "y_pred_test_gb_under = gb_clas_over.predict(X_train_over)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test_over, y_pred_test_rf_over):.2f}\")\n",
    "print(f\"Precision: {precision_score(y_test_over, y_pred_test_rf_over):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test_over, y_pred_test_rf_over):.2f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test_over, y_pred_test_rf_over):.2f}\")\n",
    "print(f\"R2 score, {gb_clas_over.score(X_test_over, y_test_over): .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e835528-83e5-41d1-bb50-abda54e49426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb_clas_under = GradientBoostingClassifier(max_depth=20, n_estimators=100)\n",
    "gb_clas_under.fit(X_train_under, y_train_under)\n",
    "y_pred_test_gb_over = gb_clas_under.predict(X_train_under)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test_under, y_pred_test_rf_under):.2f}\")\n",
    "print(f\"Precision: {precision_score(y_test_under, y_pred_test_rf_under):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test_under, y_pred_test_rf_under):.2f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test_under, y_pred_test_rf_under):.2f}\")\n",
    "print(f\"R2 score, {gb_clas_under.score(X_test_under, y_test_under): .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3909b85-e7c3-4dfc-97d5-db6c2764552c",
   "metadata": {},
   "source": [
    "### Adaptative Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7038d92c-958b-4ac4-81df-23edeb66fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_clas_over = AdaBoostClassifier(DecisionTreeClassifier(max_depth=20), n_estimators=100)\n",
    "ada_clas_over.fit(X_train_over, y_train_over)\n",
    "y_pred_test_ada_over = ada_clas_over.predict(X_train_over)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test_over, y_pred_test_rf_over):.2f}\")\n",
    "print(f\"Precision: {precision_score(y_test_over, y_pred_test_rf_over):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test_over, y_pred_test_rf_over):.2f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test_over, y_pred_test_rf_over):.2f}\")\n",
    "print(f\"R2 score, {ada_clas_over.score(X_test_over, y_test_over): .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1811afa5-111a-4c12-bb01-f1e411f19483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_clas_under = AdaBoostClassifier(DecisionTreeClassifier(max_depth=20), n_estimators=100)\n",
    "ada_clas_under.fit(X_train_under, y_train_under)\n",
    "y_pred_test_ada_under = ada_clas_under.predict(X_train_under)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test_under, y_pred_test_rf_under):.2f}\")\n",
    "print(f\"Precision: {precision_score(y_test_under, y_pred_test_rf_under):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test_under, y_pred_test_rf_under):.2f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test_under, y_pred_test_rf_under):.2f}\")\n",
    "print(f\"R2 score, {ada_clas_under.score(X_test_under, y_test_under): .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d908464-06c5-451c-8d69-378cfa4a2a8e",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d818e6-25c7-4bbb-ad35-814b537b7b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to setup a dictionary with all the values that we want to try for each hyprerparameter\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import scipy.stats as st\n",
    "\n",
    "\n",
    "parameter_grid = {\"max_depth\": [10, 50],\n",
    "                  \"min_samples_split\": [4, 16],\n",
    "                  \"max_leaf_nodes\": [250, 100],\n",
    "                  \"max_features\": [\"sqrt\", \"log2\"]}\n",
    "\n",
    "# We create an instance or our machine learning model\n",
    "dt = DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "# We need to set this two variables to be able to compute a confidence interval\n",
    "confidence_level = 0.95\n",
    "folds = 10\n",
    "\n",
    "# Now we need to create an intance of the GridSearchCV class\n",
    "gs_over = GridSearchCV(dt, param_grid=parameter_grid, cv=folds, verbose=10) # Here the \"cv\" allows you to define the number of folds to use.\n",
    "\n",
    "start_time = time.time()\n",
    "gs_over.fit(X_train_over, y_train_over)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Time taken to find the best combination of hyperparameters among the given ones: {end_time - start_time: .4f} seconds\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(f\"The best combination of hyperparameters has been: {gs_over.best_params_}\")\n",
    "print(f\"The R2 is: {gs_over.best_score_: .4f}\")\n",
    "\n",
    "results_gs_df_over = pd.DataFrame(gs_over.cv_results_).sort_values(by=\"mean_test_score\", ascending=False)\n",
    "\n",
    "gs_mean_score_over = results_gs_df_over.iloc[0,-3]\n",
    "gs_sem_over = results_gs_df_over.iloc[0,-2] / np.sqrt(folds)\n",
    "\n",
    "gs_tc_over = st.t.ppf(1-((1-confidence_level)/2), df=folds-1)\n",
    "gs_lower_bound_over = gs_mean_score_over - ( gs_tc_over * gs_sem_over)\n",
    "gs_upper_bound_over = gs_mean_score_over + ( gs_tc_over * gs_sem_over)\n",
    "\n",
    "print(f\"The R2 confidence interval for the best combination of hyperparameters is: \\\n",
    "    ({gs_lower_bound_over: .4f}, {gs_mean_score_over: .4f}, {gs_upper_bound_over: .4f}) \")\n",
    "\n",
    "display(results_gs_df_over)\n",
    "\n",
    "# Let's store the best model\n",
    "best_model_over = gs_over.best_estimator_\n",
    "\n",
    "# Now is time evaluate the model in the test set\n",
    "y_pred_test_df_over = best_model_over.predict(X_test_over)\n",
    "y_pred_test_df_over = best_model_over.predict(X_test_over)\n",
    "\n",
    "y_pred_test_over = best_model_over.predict(X_test_over)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_over, y_pred_test_rf_over):.2f}\")\n",
    "print(f\"Precision: {precision_score(y_test_over, y_pred_test_rf_over):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test_over, y_pred_test_rf_over):.2f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test_over, y_pred_test_rf_over):.2f}\")\n",
    "print(f\"Test R2 score:  {best_model_over.score(X_test_over, y_test_over): .4f}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759ebbe6-2ee2-48a2-beaa-56c5c055c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to create an intance of the GridSearchCV class\n",
    "gs_under = GridSearchCV(dt, param_grid=parameter_grid, cv=folds, verbose=10) # Here the \"cv\" allows you to define the number of folds to use.\n",
    "\n",
    "start_time = time.time()\n",
    "gs_under.fit(X_train_under, y_train_under)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Time taken to find the best combination of hyperparameters among the given ones: {end_time - start_time: .4f} seconds\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(f\"The best combination of hyperparameters has been: {gs_over.best_params_}\")\n",
    "print(f\"The R2 is: {gs_under.best_score_: .4f}\")\n",
    "\n",
    "results_gs_df_under = pd.DataFrame(gs_under.cv_results_).sort_values(by=\"mean_test_score\", ascending=False)\n",
    "\n",
    "gs_mean_score_under = results_gs_df_under.iloc[0,-3]\n",
    "gs_sem_under = results_gs_df_under.iloc[0,-2] / np.sqrt(folds)\n",
    "\n",
    "gs_tc_under = st.t.ppf(1-((1-confidence_level)/2), df=folds-1)\n",
    "gs_lower_bound_under = gs_mean_score_under - ( gs_tc_under * gs_sem_under)\n",
    "gs_upper_bound_under = gs_mean_score_under + ( gs_tc_under * gs_sem_under)\n",
    "\n",
    "print(f\"The R2 confidence interval for the best combination of hyperparameters is: \\\n",
    "    ({gs_lower_bound_under: .4f}, {gs_mean_score_under: .4f}, {gs_upper_bound_under: .4f}) \")\n",
    "\n",
    "display(results_gs_df_under)\n",
    "\n",
    "# Let's store the best model\n",
    "best_model_under = gs_under.best_estimator_\n",
    "\n",
    "# Now is time evaluate the model in the test set\n",
    "y_pred_test_df_under = best_model_under.predict(X_test_under)\n",
    "y_pred_test_df_under = best_model_under.predict(X_test_under)\n",
    "\n",
    "y_pred_test_under = best_model_under.predict(X_test_under)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_under, y_pred_test_rf_under):.2f}\")\n",
    "print(f\"Precision: {precision_score(y_test_under, y_pred_test_rf_under):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test_under, y_pred_test_rf_under):.2f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test_under, y_pred_test_rf_under):.2f}\")\n",
    "print(f\"Test R2 score:  {best_model_under.score(X_test_under, y_test_under): .4f}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4425497b-b72a-4d33-93be-3cae089a495a",
   "metadata": {},
   "source": [
    "### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d1d87c-6269-4be0-8ae6-5d66f3c88d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, r2_score\n",
    "\n",
    "tree_over = DecisionTreeClassifier(max_depth=10)\n",
    "tree_over.fit(X_train_over, y_train_over)\n",
    "y_pred_tree_over = tree_over.predict(X_test_over)\n",
    "\n",
    "tree_importance_over = {feature : importance for feature, importance in zip(X_train_over.columns, tree_over.feature_importances_)}\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test_over, y_pred_tree_over):.2f}\")\n",
    "print(f\"Precision: {precision_score(y_test_over, y_pred_tree_over):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test_over, y_pred_tree_over):.2f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test_over, y_pred_tree_over):.2f}\")\n",
    "print(f\"R2 score {tree_over.score(X_test_over, y_test_over):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c16d693-e012-43ec-9c60-3f255c007c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "tree_over = DecisionTreeClassifier(max_depth=3)\n",
    "tree_over.fit(X_train_over, y_train_over)\n",
    "dot_data = export_graphviz(tree_over, out_file=\"tree.dot\", filled=True, rounded=True, feature_names=X_train_over.columns)\n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f52509-d4ce-4d58-8dd7-9885ed03229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_under = DecisionTreeClassifier(max_depth=10)\n",
    "tree_under.fit(X_train_under, y_train_under)\n",
    "y_pred_tree_under = tree_under.predict(X_test_under)\n",
    "\n",
    "tree_importance_under = {feature : importance for feature, importance in zip(X_train_under.columns, tree_under.feature_importances_)}\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test_under, y_pred_tree_under):.2f}\")\n",
    "print(f\"Precision: {precision_score(y_test_under, y_pred_tree_under):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test_under, y_pred_tree_under):.2f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test_under, y_pred_tree_under):.2f}\")\n",
    "print(f\"R2 score {tree_over.score(X_test_under, y_test_under):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d71601d-a28a-4691-926b-3079f0ab0cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_under = DecisionTreeClassifier(max_depth=3)\n",
    "tree_under.fit(X_train_under, y_train_under)\n",
    "dot_data = export_graphviz(tree_under, out_file=\"tree.dot\", filled=True, rounded=True, feature_names=X_train_under.columns)\n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbba579-c65c-4c16-973e-4246df064290",
   "metadata": {},
   "source": [
    "### Bayesian Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b0c146-62e5-4eca-8521-cd2044747567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial, confidence_level, folds):\n",
    "\n",
    "    # First, we define the grid with values to consider when train several possible combinations.\n",
    "    # Now we specify a range/list of values to try for each hyper-parameter, and we let optuna to decide which\n",
    "    # combination to try.\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 10, 50)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 4, 16)\n",
    "    max_leaf_nodes = trial.suggest_int(\"max_leaf_nodes\", 250, 1000)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"])\n",
    "\n",
    "    dt = DecisionTreeClassifier(random_state=123,\n",
    "                               max_depth=max_depth,\n",
    "                               min_samples_split=min_samples_split,\n",
    "                               max_leaf_nodes=max_leaf_nodes,\n",
    "                               max_features=max_features)\n",
    "\n",
    "    # Here the parameter \"cv\" specifies the number of folds K\n",
    "    scores = cross_val_score(dt, X_train_over, y_train_over, cv=folds) # The scores provided will be the R2 on each hold out fold\n",
    "    mean_score = np.mean(scores)\n",
    "    sem = np.std(scores, ddof=1) / np.sqrt(folds)\n",
    "\n",
    "    tc = st.t.ppf(1-((1-confidence_level)/2), df=folds-1)\n",
    "    lower_bound = mean_score - ( tc * sem )\n",
    "    upper_bound = mean_score + ( tc * sem )\n",
    "\n",
    "    # Here, we're storing confidence interval for each trial. It's not possible for the objective function to return\n",
    "    # multiple values as Optuna uses the only returned value to find the best combination of hyperparameters.\n",
    "    trial.set_user_attr(\"CV_score_summary\", [round(lower_bound,4), round(np.mean(scores),4), round(upper_bound,4)])\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e103b40c-74fb-4c4d-baba-424dc4913f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import optuna.visualization as vis\n",
    "\n",
    "confidence_level = 0.95\n",
    "folds = 10\n",
    "\n",
    "start_time = time.time()\n",
    "study = optuna.create_study(direction=\"maximize\") # We want to have the maximum values for the R2 scores\n",
    "study.optimize(lambda trial: objective(trial, confidence_level, folds), n_trials=45)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Time taken to find the best combination of hyperparameters among the given ones: {end_time - start_time: .4f} seconds\")\n",
    "print(\"\\n\")\n",
    "print(\"The best combination of hyperparameters found was: \", study.best_params)\n",
    "print(f\"The best R2 found was: {study.best_value: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acccb570-5aee-43b1-aa07-a6f7a62eb998",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a69abc4-b769-463b-a6cb-e9bf2b43481a",
   "metadata": {},
   "source": [
    "In the previous plot, each marker represents a unique combination of the hyperparameters. However, we can't know which were the hyperparameter values in each combination. To gain more insights into this, we can do an slice plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19098d37-c96e-407e-8d52-59df3ed3c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_plot = vis.plot_slice(study)\n",
    "slice_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3809464-4d2c-45fa-8e7b-5d28d644cb24",
   "metadata": {},
   "source": [
    "It's also interesting to know what was the most important hyper-parameter to improve the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e511f5c-a789-4978-939d-2babc47b8a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameter importance\n",
    "vis.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe36cd8-0367-41c7-96f7-0ebeb157b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_over = DecisionTreeClassifier(random_state=123, **study.best_params)\n",
    "best_model_over.fit(X_train_over, y_train_over)\n",
    "y_pred_test_over = best_model_over.predict(X_test_over)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test_over, y_pred_test_over):.2f}\")\n",
    "print(f\"Precision: {precision_score(y_test_over, y_pred_test_over):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test_over, y_pred_test_over):.2f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test_over, y_pred_test_over):.2f}\")\n",
    "print(f\"Test R2 score:  {best_model_over.score(X_test_over, y_test_over): .3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9488e8c4-36ec-43f0-bde5-0442db4c1d0c",
   "metadata": {},
   "source": [
    "As we can see, the R2 on the test set is not within the confidence interval. However, you need to keep inmind that this will only happen in 5% of all tests sets as the confidence interval compromises 95% of all the test cases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
